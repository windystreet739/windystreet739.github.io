<html>
<!-- Head tag -->
<head>
  <meta charset="UTF-8">

  
  <title>
    深度学习发展历程 |
    Deep Learning
  </title>
  


  <meta name="description" content="1943年，由神经科学家麦卡洛克(W.S.McCilloch) 和数学家皮兹（W.Pitts）在《数学生物物理学公告》上发表论文《神经活动中内在思想的逻辑演算》（A Logical Calculus of the Ideas Immanent in Nervous Activity）。建立了神经网络和数学模型，称为MCP模型">
  <meta name="author" content="John Doe">
  <meta property="og:title" content="深度学习发展历程" />
  <meta property="og:description" content="1943年，由神经科学家麦卡洛克(W.S.McCilloch) 和数学家皮兹（W.Pitts）在《数学生物物理学公告》上发表论文《神经活动中内在思想的逻辑演算》（A Logical Calculus of the Ideas Immanent in Nervous Activity）。建立了神经网络和数学模型，称为MCP模型" />
  <meta property='og:site_name' content='Deep Learning' />
  <meta property="og:image" content="https://windystreet.xyz/img/default.jpg" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:description" content="1943年，由神经科学家麦卡洛克(W.S.McCilloch) 和数学家皮兹（W.Pitts）在《数学生物物理学公告》上发表论文《神经活动中内在思想的逻辑演算》（A Logical Calculus of the Ideas Immanent in Nervous Activity）。建立了神经网络和数学模型，称为MCP模型" />
  <meta name="twitter:title" content="深度学习发展历程" />

  <meta name="twitter:image" content="https://windystreet.xyz/img/default.jpg" />

  <script src="https://www.amcharts.com/lib/4/core.js"></script>
  <script src="https://www.amcharts.com/lib/4/charts.js"></script>
  <script src="https://www.amcharts.com/lib/4/themes/animated.js"></script>

  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO"
    crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz"
    crossorigin="anonymous">
  
<link rel="stylesheet" href="/css/style.css">


<meta name="generator" content="Hexo 4.2.0"></head>

<body>
    <!-- Menu -->
    <nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark page-navbar gradient">
  <div class="container">
    <a class="navbar-brand logo" href="https://windystreet.xyz">
      Deep Learning</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav"
      aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav mx-auto">
        <li class="nav-item item">
          
        <li class="nav-item item">
          <a class="nav-link" href="/">
            Home</a>
        </li>
        
        <li class="nav-item item">
          <a class="nav-link" href="/archives">
            🗂️Archives</a>
        </li>
        
        <li class="nav-item item">
          <a class="nav-link" href="https://hexo.io/" target="_blank" rel="noopener">
            Hexo</a>
        </li>
        
        </li>
      </ul>
    </div>
  </div>
</nav>

    <main class="page main-page">
        <div class="container blogPost">
    <div class="row">
        <div class="col-sm-9 px-md-5">
            <h2 class="blog-post-title">
                深度学习发展历程
            </h2>
            <p class="meta">
                <i class="far fa-clock"></i>
                2020-05-15 
            </p>
            <!-- Content -->
            <h1 id="深度学习发展历程"><a href="#深度学习发展历程" class="headerlink" title="深度学习发展历程"></a>深度学习发展历程</h1><h1 id="发展历史"><a href="#发展历史" class="headerlink" title="发展历史"></a>发展历史</h1><p><img src="https://i.loli.net/2020/05/15/gXGrY5RfkHK7d84.png" alt="times.png"></p>
<center>深度学习发展历史的时间节点</center>

<h4 id="1-开端：MCP神经元数学模型"><a href="#1-开端：MCP神经元数学模型" class="headerlink" title="1.  开端：MCP神经元数学模型"></a>1.  开端：MCP神经元数学模型</h4><p>1943年，由神经科学家麦卡洛克(W.S.McCilloch) 和数学家皮兹（W.Pitts）在《数学生物物理学公告》上发表论文《神经活动中内在思想的逻辑演算》（A Logical Calculus of the Ideas Immanent in Nervous Activity）。建立了神经网络和数学模型，称为MCP模型。所谓MCP模型，其实是按照生物神经元的结构和工作原理构造出来的一个抽象和简化了的模型，也就诞生了所谓的“模拟大脑”，人工神经网络的大门由此开启。MCP当时是希望能够用计算机来模拟人的神经元反应的过程，该模型将神经元简化为了三个过程：输入信号线性加权，求和，非线性激活（阈值法）。如下图所示：</p>
<p><img src="https://i.loli.net/2020/05/15/sTGf1JbIcUpdWia.png" alt="mcp.png"></p>
<h4 id="2-第一代神经网络（1958-1969）"><a href="#2-第一代神经网络（1958-1969）" class="headerlink" title="2.  第一代神经网络（1958~1969）"></a>2.  第一代神经网络（1958~1969）</h4><p>1958年，第一次将MCP用于机器学习（分类）的当属罗森布拉特（Rosenblatt）发明的感知器（perceptron）算法。该算法使用MCP模型对输入的多维数据进行二分类，且能够使用梯度下降法从训练样本中自动学习更新权值。1962年，该方法被证明为能够收敛，理论与实践效果引起第一次神经网络的浪潮。</p>
<p>1969年，美国数学家及人工智能先驱Minsky在其著作中证明了感知器本质上是一种线性模型，只能处理线性分类问题，就连最简单的XOR（亦或）问题都无法正确分类。这等于直接宣判了感知器的死刑，神经网络的研究也陷入了近20年的停滞。</p>
<h4 id="3-第二代神经网络（1986-1998）"><a href="#3-第二代神经网络（1986-1998）" class="headerlink" title="3.  第二代神经网络（1986~1998）"></a>3.  第二代神经网络（1986~1998）</h4><p>1986年，第一次打破非线性诅咒的当属现代DL大牛Hinton，其发明了适用于多层感知器（MLP）的BP算法，并采用Sigmoid进行非线性映射，有效解决了非线性分类和学习的问题。该方法引起了神经网络的第二次热潮。</p>
<p>1989年，Robert Hecht-Nielsen证明了MLP的万能逼近定理，即对于任何闭区间内的一个连续函数f，都可以用含有一个隐含层的BP网络来逼近该定理的发现极大的鼓舞了神经网络的研究人员。LeCun发明了卷积神经网络-LeNet，并将其用于数字识别，且取得了较好的成绩，不过当时并没有引起足够的注意。</p>
<p>1989年以后，由于没有特别突出的方法被提出，且NN一直缺少相应的严格的数学理论支持，神经网络的热潮渐渐冷淡下去。</p>
<p>1991年，BP算法被指出存在梯度消失问题，即在误差梯度后向传递的过程中，后层梯度以乘性方式叠加到前层，由于Sigmoid函数的饱和特性，后层梯度本来就小，误差梯度传到前层时几乎为0，因此无法对前层进行有效的学习，该发现对此时的NN发展雪上加霜。</p>
<p>1997年，LSTM模型被发明，尽管该模型在序列建模上的特性非常突出，但由于正处于NN的下坡期，也没有引起足够的重视。</p>
<h4 id="4-统计学习方法的春天（1986-2006）"><a href="#4-统计学习方法的春天（1986-2006）" class="headerlink" title="4.  统计学习方法的春天（1986~2006）"></a>4.  统计学习方法的春天（1986~2006）</h4><p>1986年，决策树方法被提出，很快ID3，ID4，CART等改进的决策树方法相继出现，到目前仍然是非常常用的一种机器学习方法。该方法也是符号学习方法的代表。</p>
<p>1995年，线性SVM被统计学家Vapnik提出。该方法的特点有两个：由非常完美的数学理论推导而来（统计学与凸优化等），符合人的直观感受（最大间隔）。不过，最重要的还是该方法在线性分类的问题上取得了当时最好的成绩。</p>
<p>1997年，AdaBoost被提出，该方法是PAC（Probably Approximately Correct）理论在机器学习实践上的代表，也催生了集成方法这一类。该方法通过一系列的弱分类器集成，达到强分类器的效果。</p>
<p>2000年，KernelSVM被提出，核化的SVM通过一种巧妙的方式将原空间线性不可分的问题，通过Kernel映射成高维空间的线性可分问题，成功解决了非线性分类的问题，且分类效果非常好。至此也更加终结了NN时代。</p>
<p>2001年，随机森林被提出，这是集成方法的另一代表，该方法的理论扎实，比AdaBoost更好的抑制过拟合问题，实际效果也非常不错。</p>
<p>2001年，一种新的统一框架-图模型被提出，该方法试图统一机器学习混乱的方法，如朴素贝叶斯，SVM，隐马尔可夫模型等，为各种学习方法提供一个统一的描述框架。</p>
<h4 id="5-第三代神经网络-DL（2006-至今）"><a href="#5-第三代神经网络-DL（2006-至今）" class="headerlink" title="5.  第三代神经网络-DL（2006-至今）"></a>5.  第三代神经网络-DL（2006-至今）</h4><p>该阶段又分为两个时期：快速发展期（2006<del>2012）与爆发期（2012</del>至今）。</p>
<h5 id="快速发展期（2006-2012）："><a href="#快速发展期（2006-2012）：" class="headerlink" title="快速发展期（2006~2012）："></a>快速发展期（2006~2012）：</h5><p>2006年，Hinton提出了深层网络训练中梯度消失问题的解决方案：无监督预训练对权值进行初始化+有监督训练微调。其主要思想是先通过自学习的方法学习到训练数据的结构（自动编码器），然后在该结构上进行有监督训练微调。但是由于没有特别有效的实验验证，该论文并没有引起重视。</p>
<p>2011年，ReLU激活函数被提出，该激活函数能够有效的抑制梯度消失问题。</p>
<p>2011年，微软首次将DL应用在语音识别上，取得了重大突破。</p>
<h5 id="爆发期（2012-至今）："><a href="#爆发期（2012-至今）：" class="headerlink" title="爆发期（2012~至今）："></a>爆发期（2012~至今）：</h5><p>2012年，Hinton课题组为了证明深度学习的潜力，首次参加ImageNet图像识别比赛，其通过构建的CNN网络AlexNet一举夺得冠军，且碾压第二名（SVM方法）的分类性能。也正是由于该比赛，CNN吸引到了众多研究者的注意。</p>
<p><img src="https://i.loli.net/2020/05/15/x8L2gEBjzC5RSaQ.jpg" alt="AlexNet.jpg"></p>
<p>AlexNet的创新点：<br>（1）首次采用ReLU激活函数，极大增大收敛速度且从根本上解决了梯度消失问题；</p>
<p>（2）由于ReLU方法可以很好抑制梯度消失问题，AlexNet抛弃了“预训练+微调”的方法，完全采用有监督训练。也正因为如此，DL的主流学习方法也因此变为了纯粹的有监督学习；</p>
<p>（3）扩展了LeNet5结构，添加Dropout层减小过拟合，LRN层增强泛化能力/减小过拟合；</p>
<p>（4）首次采用GPU对计算进行加速；</p>
<p>2013,2014,2015年，通过ImageNet图像识别比赛，DL的网络结构，训练方法，GPU硬件的不断进步，促使其在其他领域也在不断的征服战场。</p>
<p>2015年，Hinton，LeCun，Bengio论证了局部极值问题对于DL的影响，结果是Loss的局部极值问题对于深层网络来说影响可以忽略。该论断也消除了笼罩在神经网络上的局部极值问题的阴霾。具体原因是深层网络虽然局部极值非常多，但是通过DL的BatchGradientDescent优化方法很难陷进去，而且就算陷进去，其局部极小值点与全局极小值点也是非常接近，但是浅层网络却不然，其拥有较少的局部极小值点，但是却很容易陷进去，且这些局部极小值点与全局极小值点相差较大。论述原文其实没有证明，只是简单叙述，严密论证是猜的。</p>
<p>DeepResidualNet发明。分层预训练，ReLU和BatchNormalization都是为了解决深度神经网络优化时的梯度消失或者爆炸问题。但是在对更深层的神经网络进行优化时，又出现了新的Degradation问题，即”通常来说，如果在VGG16后面加上若干个单位映射，网络的输出特性将和VGG16一样，这说明更深次的网络其潜在的分类性能只可能&gt;=VGG16的性能，不可能变坏，然而实际效果却是只是简单的加深VGG16的话，分类性能会下降（不考虑模型过拟合问题）“Residual网络认为这说明DL网络在学习单位映射方面有困难，因此设计了一个对于单位映射（或接近单位映射）有较强学习能力的DL网络，极大的增强了DL网络的表达能力。此方法能够轻松的训练高达150层的网络。</p>
<p>2016年3月，由谷歌（Google）旗下DeepMind公司开发的AlphaGo(基于深度学习)与围棋世界冠军、职业九段棋手李世石进行围棋人机大战，以4比1的总比分获胜；</p>
<p>2016年末2017年初，该程序在中国棋类网站上以“大师”（Master）为注册帐号与中日韩数十位围棋高手进行快棋对决，连续60局无一败绩；</p>
<p>2017年5月，在中国乌镇围棋峰会上，它与排名世界第一的世界围棋冠军柯洁对战，以3比0的总比分获胜。围棋界公认阿尔法围棋的棋力已经超过人类职业围棋顶尖水平。</p>
<p><img src="https://i.loli.net/2020/05/16/kPl81BZ6JpRcfrA.jpg" alt="KJ.jpg"></p>

            <br />
            <p class="meta">
                
            </p>
        </div>

        <div class="col-sm-3">
             
<span><b> TL;DR</b></span>
<p>
	Yet another hexo theme.
</p>
<hr />


<span><b> TL;DR 2</b></span>
<p>
	No, not another one :/
</p>
<hr />

 

        </div>
    </div>
</div>
<!-- Menu fade on scroll -->
<script>
    var isScrolling;
    var prevScrollpos = window.pageYOffset;
    window.addEventListener(
        'scroll',
        function(event) {
            window.clearTimeout(isScrolling);
            isScrolling = setTimeout(function() {
                var currentScrollPos = window.pageYOffset;
                if (prevScrollpos > currentScrollPos) {
                    $('#navbar').slideDown();
                } else {
                    $('#navbar').slideUp();
                }
                prevScrollpos = currentScrollPos;
            }, 66);
        },
        false
    );
</script>


<a class="float-left gradient btn paginationbtn" href="/uncategorized/深度学习应用领域/"><i class="fas fa-chevron-left"></i></a>


<a class="float-right gradient btn paginationbtn" href="/uncategorized/深度学习简介/"><i class="fas fa-chevron-right"></i></a>

    </main>
    <!-- Footer -->
    <footer class="page-footer">
  <div class="container">
    <div class="social-icons">
      
      <a href="https://hexo.io/" title="Hexo.io" target="_blank" rel="noopener" class="fas fa-home"></a>
      
      <a href="https://twitter.com/hexojs" title="@hexojs" target="_blank" rel="noopener" class="fab fa-twitter"></a>
      
      <a href="https://github.com/RandomAdversary/Gradient/issues" title="Report issue" target="_blank" rel="noopener" class="fas fa-bug"></a>
      
    </div>
  </div>
</footer>
    <!-- After footer scripts -->
    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
    crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy"
    crossorigin="anonymous"></script>
</body>

</html>