<html>
<!-- Head tag -->
<head>
  <meta charset="UTF-8">

  
  <title>
    深度学习文献综述 |
    Deep Learning
  </title>
  


  <meta name="description" content="机器学习(Machine Learning)是一门多领域交叉学科，涉及概率论、统计学等多门理论学科。机器学习最开始...">
  <meta name="author" content="John Doe">
  <meta property="og:title" content="深度学习文献综述" />
  <meta property="og:description" content="机器学习(Machine Learning)是一门多领域交叉学科，涉及概率论、统计学等多门理论学科。机器学习最开始..." />
  <meta property='og:site_name' content='Deep Learning' />
  <meta property="og:image" content="https://windystreet.xyz/img/default.jpg" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:description" content="机器学习(Machine Learning)是一门多领域交叉学科，涉及概率论、统计学等多门理论学科。机器学习最开始..." />
  <meta name="twitter:title" content="深度学习文献综述" />

  <meta name="twitter:image" content="https://windystreet.xyz/img/default.jpg" />

  <script src="https://www.amcharts.com/lib/4/core.js"></script>
  <script src="https://www.amcharts.com/lib/4/charts.js"></script>
  <script src="https://www.amcharts.com/lib/4/themes/animated.js"></script>

  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO"
    crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz"
    crossorigin="anonymous">
  
<link rel="stylesheet" href="/css/style.css">


<meta name="generator" content="Hexo 4.2.0"></head>

<body>
    <!-- Menu -->
    <nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark page-navbar gradient">
  <div class="container">
    <a class="navbar-brand logo" href="https://windystreet.xyz">
      Deep Learning</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav"
      aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav mx-auto">
        <li class="nav-item item">
          
        <li class="nav-item item">
          <a class="nav-link" href="/">
            Home</a>
        </li>
        
        <li class="nav-item item">
          <a class="nav-link" href="/archives">
            🗂️Archives</a>
        </li>
        
        <li class="nav-item item">
          <a class="nav-link" href="/about">
            About</a>
        </li>
        
        </li>
      </ul>
    </div>
  </div>
</nav>

    <main class="page main-page">
        <div class="container blogPost">
    <div class="row">
        <div class="col-sm-9 px-md-5">
            <h2 class="blog-post-title">
                深度学习文献综述
            </h2>
            <p class="meta">
                <i class="far fa-clock"></i>
                2020-05-14 
            </p>
            <!-- Content -->
            <center><b><big>机器学习文献综述</big></b></center>
<center><b>王菁</b></center>
<center>(成都信息工程大学计算机学院 成都 610225)</center>
<p><strong>摘要</strong>：机器学习(Machine Learning)是一门多领域交叉学科，涉及概率论、统计学等多门理论学科。机器学习最开始的研究其实并不似现在一般繁荣，在经过几十年的探索和研究后，结合时下大数据的广泛应用，才有了现在机器学习的繁荣，并且还划分出了许多分支。现如今的机器学习中包含着多样的训练模型和学习策略，应用于各大领域，人工智能的发展也进一步确定了机器学习在当前信息时代的重要地位。在本文中，就主要介绍机器学习的发展历程、经典算法以及在现代一些领域当中的一些应用，并且就当前技术水平以及未来发展发表一下自己的观点。</p>
<p><strong>关键字</strong>：机器学习；人工智能；学习算法；KNN；神经网络；深度学习</p>
<p><strong>1</strong>  <strong>引言</strong></p>
<p>人工智能在当今时代已经被广泛应用，支撑人工智能的主要三大驱动力：大数据，机器学习，硬件CPU<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>,其中发展最快的分支就是机器学习，也是人工智能领域的核心。它的主要思想是采用大量数据，经过一定的算法和统计模型来训练机器，使其拥有“学习”技能或者知识的能力，并且可以通过数据不断完善自身，如同人类一样，这也是人工智能的主要思想。因此，在机器学习这门学科中，训练模型是很核心的一项。在当今信息化、大数据化的时代，这项技术也面临着挑战，在各异的数据中训练出能够总结出较为准确的机器也是这门学科中的一大难题。因此，在研究领域上，机器学习的研究仍是当今热点。</p>
<p>数据库：百度词条、360百科、知网数据库、超星数据库、全国图书馆参考联盟。检索式：机器学习。</p>
<p><strong>2</strong>  <strong>机器学习的发展历程</strong></p>
<p><strong>2.1</strong> <strong>机器学习的“热烈时期”</strong></p>
<p>机器学习的“热烈时期”指的是20世纪50年代中期到60年代中期。在这个时期，人们通过控制参数来改善系统的执行能力，使其更具逻辑推理性。这个阶段具有代表性的成果是A. Newell和H. Simon的“逻辑理论家”（Logic Theorist）程序证明了数学原理，以及此后的“通用问题求解”（General Problem Solving）程序。1952年，阿瑟·萨缪尔（Arthur Samuel）在IBM公司研制了一个西洋跳棋程序，这是人工智能下棋问题的由来。但是，这个时期的“机器学习”是不涉及任何与具体任务相关的知识，是“无知”学习，具有很大的局限性。</p>
<p><strong>2.2 机器学习的“冷静时期”</strong></p>
<p>机器学习的“冷静时期”指的是20世纪60年代中期到70年代中期。这个阶段主要研究模拟人类的概念学习过程，机器内部描述采用逻辑结构或者图结构。这个时期基于逻辑表示的“符号主义”学习技术蓬勃发展，这个阶段具有代表性的有P. Winston的结构学习系统，R. S. Michalski的基于逻辑的归纳学习系统，以及E. B. Hunt的概念学习系统。虽然相较于上一时期，机器学习已经取得了重大突破，但是只能学习单一概念，再加上作为理论基础的神经网络理论缺陷而未能达到预期效果，最终也没有投入到应用中，机器学习研究一度降到低谷。</p>
<p><strong>2.3 机器学习的“复兴时期”</strong></p>
<p>机器学习的“复兴时期”是指20世纪70年代中期到80年代中期。在这个时期，人们将单一概念的学习扩展为多概念的学习，并且开始探索不同的学习策略和方法。当时的主流是“专家系统”，出现之后，示例规约学习系统成为机器学习的研究主要方向。一些相关著作也相应出版，比如1983年Tioga出版社出版的R.S.Michalski|J.G.Carbonell和T.M.Mitchell等顶尖专家联合主编的图书教材《机器学习：一种人工智能途径》<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。此后，1988年，国际杂志《机器学习》（Machine Learning）创刊，机器学习的研究进入了新的繁荣时期。</p>
<p><strong>2.4 机器学习的“繁荣时期”</strong></p>
<p>20世纪80年代中期到至今是机器学习的“繁荣时期”。这一时期由于互联网大数据的广泛应用，连带着机器学习也达到了前所未有的繁荣。各种训练模型和学习算法相继涌现，并且还衍生出很多分支，比如模式识别、语音识别、数据挖掘等等，机器学习已经被广泛应用到我们的生活之中。</p>
<p><strong>3 机器学习中的相关因素</strong></p>
<p><strong>3.1 监督学习与非监督学习</strong></p>
<p>机器学习需要大量数据来对机器进行训练，使其训练出一个有效的训练模型，用于预测或者决定。这个训练过程其实就是学习过程，目前机器学习可分类为监督学习和非监督学习两种基本类型。<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p>
<p>3.1.1监督学习</p>
<p>监督学习是指对具有概念标记（分类）的训练样本进行学习，以尽可能对训练样本集外的数据进行标记（分类）预测。这里，所有的标记（分类）是已知的。因此，训练样本的岐义性低。</p>
<p>直白来说，就是我们在训练之前已经给出了一定的分类标准，让机器“记住”这个标准后来对其他数据进行分类。</p>
<p>3.1.2非监督学习</p>
<p>非监督学习是指对没有概念标记（分类）的训练样本进行学习，以发现训练样本集中的结构性知识。这里，所有的标记（分类）是未知的。因此，训练样本的岐义性高。聚类就是典型的无监督学习。</p>
<p>简单来说，与监督学习相反，我们在进行训练之前只给大量数据，但是不给出任何分类标准，由机器通过分析大量数据自己总结出分类标准，因此，不同数据可能得出的分类标准也不同。</p>
<p><strong>3.2 分类与回归</strong></p>
<p>监督学习在生活中应用广泛。总的来说监督学习可分为分类和回归。<sup class="footnote-ref"><a href="#fn3" id="fnref3:1">[3:1]</a></sup></p>
<p>3.2.1回归问题</p>
<p>回归问题（连续变量预测）：输入一个新数据，训练模型就会预测其输出值（实数）。回归任务属于定量输出<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>。</p>
<p>比如，预测明天的降水量就是一个回归任务。</p>
<p>3.2.2分类问题</p>
<p>分类问题（离散变量预测）：输入一个数据，训练模型将判断出它的类别。分类任务属于定性输出。</p>
<p>比如，预测明天是否下雨就是一个分类任务。</p>
<p><strong>4 实现机器学习的经典算法以及技术</strong></p>
<p><strong>4.1</strong> <strong>KNN算法</strong></p>
<p>4.1.1 KNN算法介绍</p>
<p>1986年Cove、Hart提出KNN算法<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>。KNN算法又称为K邻近算法。KNN算法是机器学习中一个最简单的算法之一，在许多应用领域中经常推出并使用KNN算法的改进算法。</p>
<p>4.1.2 KNN算法原理</p>
<p>从K邻近算法这个名字就可以大概理解， KNN的主要思想就是“近朱者赤，近墨者黑”，即由相邻的数据来确定当前数据。在文本分类中，KNN算法通过计算待分类样本与已知训练样本的相似度，找到与待分类样本相似度最大的K个最近邻文本，如果K个最近邻文本中的大多数样本属于某个类别，那么判定待分类样本也属于这个类别<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>。</p>
<p>它的原理就围绕着这个思想：存在一个训练样本集合，该集合中每行数据包含多个特征和分类标签，输入没有标签但有多个特征的新数据，将新数据的每个特征与样本中每条数据对应的特征进行比较，然后提取出样本中与新数据最相似的K条数据，统计该K条数据中各类标签出现的次数，那么出现次数最多的标签即为新数据的分类标签。</p>
<p>4.1.3 KNN算法的计算</p>
<p>首先介绍KNN算法的三大要素：距离度量、k值的选择及分类决策规则。根据选择的距离度量（如曼哈顿距离或欧氏距离），可计算测试实例与训练集中的每个实例点的距离，根据k值选择k个最近邻点，最后根据分类决策规则将测试实例分类。</p>
<p>（1）距离度量：</p>
<p>特征空间中的两个实例点的距离是两个实例点相似程度的反映。K近邻法的特征空间一般是n维实数向量空间Rn。使用的距离是欧氏距离，但也可以是其他距离，如更一般的Lp距离或Minkowski距离。这里我们采用Lp距离。</p>
<p>Lp距离定义：</p>
<p><img src="https://i.loli.net/2020/05/16/diERxDGJb9pP7ut.jpg" alt="公式1.jpg"></p>
<p>这里p≥1。</p>
<p>当p=1时，称为曼哈顿距离，即</p>
<p><img src="https://i.loli.net/2020/05/16/qsTAp8e2CQiyXcV.jpg" alt="公式2.jpg"></p>
<p>当p=2时，称为欧式距离，即</p>
<p><img src="https://i.loli.net/2020/05/16/rtAzDQGpw6uNXI4.jpg" alt="公式3.jpg"></p>
<p>当p=∞时，它是各个坐标距离的最大值，即</p>
<p><img src="https://i.loli.net/2020/05/16/W3rtpNvKaLHcSb2.jpg" alt="公式4.jpg"></p>
<p>不同距离公式的选取也会对结果造成影响。如图所示，当采用欧式距离（p=2）时，到原点距离为1的点组成的图形是一个半径为1的圆；采用曼哈顿距离（p=1）时，组成的图是一个对角线长为2的菱形；当采用切比雪夫距离（p=∞）时，所得图形为边长为2的正方形。</p>
<p><img src="https://i.loli.net/2020/05/16/xjWrCXmNH7GtDz4.jpg" alt="图一.jpg"><sup class="footnote-ref"><a href="#fn4" id="fnref4:1">[4:1]</a></sup><br>
2）k值的选择</p>
<p>k值的选择会对k近邻法的结果产生重大影响。在应用中，k值一般取一个比较小的数值，通常采用交叉验证法来选取最优的k值。</p>
<p>（3）分类决策规则</p>
<p>k近邻法中的分类决策规则往往是多数表决，即由输入实例的k个邻近的训练实例中的多数类，决定输入实例的类。</p>
<p><strong>4.2</strong> <strong>神经网络</strong></p>
<p>4.2.1 神经网络介绍</p>
<p>人工神经网络算法模拟生物神经网络，是一类模式匹配算法。通常用于解决分类和回归问题。人工神经网络是机器学习的一个分支，有几百种算法，深度学习就是其中之一，其他的还有卷积神经网络、LSTM(Long Short-Term Memory,长短期记忆网络)，神经网络经常和其他算法结合来形成一个改进后的训练模型，比如NCULSTM（新细胞更新长短期记忆网络）<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>。</p>
<p>4.2.2 神经网络工作原理</p>
<p>人工神经网络是由神经元(感知器)通过突触(权重)连接而形成的多层复杂模型<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>。如下图所示，最前面一层叫输入层，最后面的叫输出层，中间的叫隐含层(隐层)。每一层之间都有许多节点，节点与节点之间由一条带权边连接。</p>
<p><img src="https://i.loli.net/2020/05/16/uPCmF5qIZTDBltH.jpg" alt="图二.jpg"></p>
<p>当输入值后，这些数据就在神经网络内传播计算，最后输出，神将网络有两种传播方式，前向传播和反向传播。</p>
<p>（1）前向传播：对于一个输入值，将前一层的输出与后一层的权值进行运算，再加上后一层的偏置值得到了后一层的输出值，再将后一层的输出值作为新的输入值传到再后面一层，一层层传下去得到最终的输出值。</p>
<p>（2）反向传播：反向传播：前向传播会得到预测值，但是这个预测值不一定是真实的值，反向传播的作用就是修正误差，通过与真实值做对比修正前向传播的权值和偏置。</p>
<p>神经网络算法在语音、视频、图片处理上展现了及其优越的性能，但是还是需要大量数据来提高准确性。</p>
<p><strong>4.3</strong> <strong>深度学习</strong></p>
<p>深度学习的概念由Hinton等人于2006年提出。基于深信度网(DBN)提出非监督贪心逐层训练算法，为解决深层结构相关的优化难题带来希望，随后提出多层自动编码器深层结构。此外Lecun等人提出的卷积神经网络是第一个真正多层结构学习算法，它利用空间相对关系减少参数数目以提高训练性能。深度学习是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。深度学习是一个框架，包括许多算法和概念，比如卷积和池化的思想。</p>
<p>4.3.1 卷积</p>
<p><img src="https://i.loli.net/2020/05/16/D5XBRJE3wmhGjyr.gif" alt="卷积.gif"></p>
<p>如图所示，我们有一个5x5的图像，我们用一个3x3的卷积核：</p>
<p>1　　0　　1</p>
<p>0　　1　　0</p>
<p>1　　0　　1</p>
<p>来对图像进行卷积操作（可以理解为有一个滑动窗口，把卷积核与对应的图像像素做乘积然后求和），得到了3x3的卷积结果。</p>
<p>这个过程我们可以理解为我们使用一个过滤器（卷积核）来过滤图像的各个小区域，从而得到这些小区域的特征值。在实际训练过程中，卷积核的值是在学习过程中学到的。</p>
<p>4.3.2 池化</p>
<p><img src="https://i.loli.net/2020/05/16/lPgKHFvVrRAOtzL.gif" alt="pooling.gif"></p>
<p>上图中，我们可以看到，原始图片是20x20的，我们对其进行下采样，采样窗口为10x10，最终将其下采样成为一个2x2大小的特征图。之所以这么做的原因，是因为即使做完了卷积，图像仍然很大（因为卷积核比较小），所以为了降低数据维度，就进行下采样。之所以能这么做，是因为即使减少了许多数据，特征的统计属性仍能够描述图像，而且由于降低了数据维度，有效地避免了过拟合。在实际应用中，池化根据下采样的方法，分为最大值下采样（Max-Pooling）与平均值下采样（Mean-Pooling）。</p>
<p><strong>5</strong> <strong>机器学习应用</strong></p>
<p><strong>5.1</strong> <strong>机器学习在数据挖掘中的应用</strong></p>
<p>数据挖掘就是指在数据中发现隐藏的，人们事先不知道的，但是又具有潜在价值的信息的过程<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>。数据挖掘是一个很复杂的过程，需要进行多步迭代得到最终有意义的知识。对于预测最终结果的预测精度，机器学习是一个很重要的技术，机器学习还可以提高真实数据的预测精度。这也是机器学习的一个特性，上文中介绍到的神经网络算法的最大优点就是可以精确地对复杂问题进行预测。由于基于机器学习的模式识别算法限制比较少，并且易于理解，所以机器学习方法以其强大的对不同数据的处理能力受到数据挖掘领域的重视。</p>
<p><strong>5.2</strong> <strong>机器学习在智慧教育中的应用</strong></p>
<p>智慧教育是传统教育和数据挖掘的综合应用。其中，机器学习的主要作用是数据挖掘和解释，实现复杂的统计任务。比如学生平时的表现、学习内容、作业完成度、成绩等等，基于机器学习对这些数据建立一个预测模型或者描述模型，方便教育工作者对学生的情况进行了解。</p>
<p>现在，在智慧教育中，机器学习的应用方法有许多，包括分类、文本挖掘、预测、异常检查、关联规则挖掘、聚类、回归、模式发现、序列模式分析以及社会网络分析等，其中预测和聚类是最常用的方法<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>。</p>
<p><strong>5.3</strong> <strong>机器学习在风速预测中的应用</strong></p>
<p>风速预测一般是通过对大量历史数据的分析和总结从而对未来的风速进行预测。机器学习拥有强大的数据处理能力，并且有比较好的预测算法和模型。比如上文中提到的LSTM（长短期记忆网络）经常用于这一领域。LSTM 是由Hochreiter 和Schmiduber 提出的一种时间递归神经网络，能学习长期依赖性，适合用于处理和预测时间序列中间隔和延迟非常长的事件<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>。将历史数据进行一定的预处理后，一部分作为训练集，一部分作为预测集，训练集通过LSTM模型进行训练，对后面的数据进行预测，从而计算误差，判定预测模型的预测精度。当然在更多时候，是使用的改进后的LSTM，以提高预测精度和减少预测时间。</p>
<p><strong>6</strong> <strong>机器学习算法的研究近况</strong></p>
<p>Boosting、支持向量机 (SVM)、集成学习和稀疏学习是机器学习界也是统计界在近十年或者是近二十年来最为活跃的方向，这些成果是统计界和计算机科学界共同努力成就的。例如，数学家瓦普尼克 (Vapnik) 等人早在20 世纪60 年代就提出了支持向量机的理论，但直到计算机界于90 年代末发明了非常有效的求解算法，并随着后续大量实现代码的开源，支持向量机现在成为了分类算法的一个基准模型。</p>
<p><strong>6.1</strong> <strong>支持向量机SVM</strong></p>
<p>Vapnik等人在多年研究统计学习理论基础上对线性分类器提出了另一种设计最佳准则SVM，这个方法巧妙地解决了计算的复杂化的难题，不但几乎不增加计算的复杂性，而且在某种程度上避免了“维数灾难”。但是SVM也有有潜在缺点：需要对输入数据进行全面标注，而且SVM只适用于两类任务，因此，必须应用将多类任务减少到几个二进制问题的算法另外，求解模型的参数也难以解释。邓来飞等利用PSO优化SVR和LS-SVR模型参数(c，g)<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>，最终达到优化效果，解决了模型参数难以解释的问题，但是仍未解决数据量巨大时标注的困难</p>
<p><strong>6.2</strong> <strong>决策树分类</strong></p>
<p>传统决策树作为一种经典的分类学习算法，对大数据处理存在内存开销过大的问题，对连续性的字段比较难预测，对有时间顺序的数据，需要很多预处理的工作，且当类别太多时，错误可能就会增加的比较快。另外，在平衡数据的分类任务中，决策树因其简单高效且具有强解释性而备受瞩目。然而，当面临不平衡数据时，决策树算法偏向于多数类使其性能大打折扣。王伟<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup>等提出了一种改进决策树的方法在提升少数类准确率的同时，还保证了多数类的准确率，并且能改善其在不平衡数据上的分类，但是仍然需要花费大量时间在预处理工作上。程慧等提出的蚁群算法优化的决策树模型<sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup>,比传统的决策树和SVM算法具有更高的分类准确度，但同样在预处理工作上花费了大量时间。</p>
<p><strong>6.3</strong> <strong>神经网络</strong></p>
<p>传统前馈神经网络一般采用梯度下降算法调整权值参数，学习速度慢、泛化性能差等问题是制约前馈神经网络应用的瓶颈。现有的神经网络为人广知的缺点是“黑箱”性质，即当结果出错时你不知道为什么会出现这个错误的结果。Huang等摒弃梯度下降算法的迭代调整策略，提出ELM。相比于传统前馈神经网络训练算法需经多次迭代调整才可最终确定网络权值，ELM 的训练速度获得较显著提升。但是泛化性能仍然较差。上文中提到的LSTM的改进算法NCULSTM模型也是有效的提高了训练速度，但是缺也未能解决神经网络的普遍缺点“黑箱性质”。</p>
<p><strong>7 机器学习目前的瓶颈以及未来研究热点</strong></p>
<p>现阶段已经有特别多的研究工作者投入到机器学习的热潮中去，已经大有成就，在大数据化的时代背景下，机器学习的发展还会继续繁荣。当然，即使机器学习的研究已经有许多重大成果，并且投入应用，但仍然存在不足，现阶段的机器学习由于现在计算机硬件的限制，仍然是很被动的学习。在一些研究项目中，机器学习的研究所需的大量数据来源也是一个难题。而机器学习中的一些算法模型中的不足也成为掣肘机器学习进一步发展的瓶颈。</p>
<p>从当前的研究趋势来看，机器学习的未来研究热点可能会是：（1）在现有的机器学习算法上进行优化，使其预测误差减小，预测精度提高，预测时间缩短。（2）多个机器学习算法结合，避免单个算法中的不足，改善原有的算法。（3）从人类自身出发找出大脑本身生物学习机制，通过严格数学化应用于机器学习。</p>
<p><strong>8</strong> <strong>总结</strong></p>
<p>本综述从机器学习的发展简史谈起，介绍了机器学习算法现阶段的研究情况以及取得的进展，最后探讨了机器学习面临的瓶颈。毋庸置疑，机器学习作为人工智能的一个重要分支，目前在诸多领域取得了巨大进展，并且展示出强大的发展潜力。但是更应该看到，机器学习的发展仍然处理初级阶段，目前虽然有各种各样机器学习算法但却无法从根本上解决机器学习所面临的壁垒，机器学习仍然主要依赖监督学习，还没有跨越弱人工智能。因此我认为，机器学习并不是我们所想的那么强大，进步空间还很大，对于机器学习，我们仍然还有很长的一段路要走。</p>
<hr>
<p><strong>参考文献：</strong></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>赵晨阳.机器学习综述[J].数字通信世界,2018(1):109-112. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>吴康宁.基于人工智能下的机器学习历史及展望[J].科技尚品,2017(6):187. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>周志华.机器学习[M].清华大学出版社.2016.1. <a href="#fnref3" class="footnote-backref">↩︎</a> <a href="#fnref3:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>孔欣然.机器学习综述[J].电子制作,2019(24):82-84,38. <a href="#fnref4" class="footnote-backref">↩︎</a> <a href="#fnref4:1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>周昀锴.机器学习及其相关算法简介[J].科技传播.2019(6):153-154. <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>殷亚博，杨文忠，杨慧婷，许超英.基于卷积神经网络和KNN的短文本分类算法研究[J].计算机工程.2018(7):193-198. <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p>Shaoqian Peia, Hui Qina,⁎, Zhendong Zhanga, Liqiang Yaob, Yongqiang Wangb, Chao Wangc,Yongqi Liua, Zhiqiang Jianga, Jianzhong Zhoua, Tailai Yia. Wind speed prediction method based on Empirical Wavelet Transform and New Cell Update Long Short-Term Memory network[J].Energy Conversion and Management.2019(196) :779–792. <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p>Falavigna G, Costantino G, Furlan R, et al.Artificial neural networks and risk stratification in emergency departments[J].Intern Emerg Med,2019,14(2):291-299. <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p>周旭. 数据挖掘中机器学习的应用[J].电子技术与软件工程.2019(7):173. <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p>许祖铭.论人工智能中的机器学习应用[J].电子世界.2018(16):74-75. <a href="#fnref10" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p>王国松，王喜冬，侯敏，齐义泉，宋军，刘克修，吴新荣，白志鹏 . 基于观测和再分析数据的LSTM 深度神经网络沿海风速预报应用研究[J].海洋学报.2020(1):67-77. <a href="#fnref11" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p>邓来飞,张 飞,齐亚霄,袁 婕. 基于参数优化SVM方法识别盐生植被钠离子光谱特征[J].光谱学与光谱分析，2020(1):247-254. <a href="#fnref12" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p>王伟，谢耀滨，尹 青. 针对不平衡数据的决策树改进方法[J].计算机应用.2019(3):623-628. <a href="#fnref13" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p>程慧,张瑞,张世科,史冬妮,付凤平. 基于改进决策树的停电敏感度分析[J].微型电脑应用.2020(3):144-148. <a href="#fnref14" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

            <br />
            <p class="meta">
                
            </p>
        </div>

        <div class="col-sm-3">
             
<span><b> deeplearning.ai 学习课程</b></span>
<p>
	http://dwz.date/aCAN
</p>
<hr />

 

        </div>
    </div>
</div>
<!-- Menu fade on scroll -->
<script>
    var isScrolling;
    var prevScrollpos = window.pageYOffset;
    window.addEventListener(
        'scroll',
        function(event) {
            window.clearTimeout(isScrolling);
            isScrolling = setTimeout(function() {
                var currentScrollPos = window.pageYOffset;
                if (prevScrollpos > currentScrollPos) {
                    $('#navbar').slideDown();
                } else {
                    $('#navbar').slideUp();
                }
                prevScrollpos = currentScrollPos;
            }, 66);
        },
        false
    );
</script>


<a class="float-left gradient btn paginationbtn" href="/uncategorized/国内外深度学习研究现状/"><i class="fas fa-chevron-left"></i></a>


<a class="float-right gradient btn paginationbtn" href="/uncategorized/深度学习近年文献/"><i class="fas fa-chevron-right"></i></a>

    </main>
    <!-- Footer -->
    <footer class="page-footer">
  <div class="container">
    <div class="social-icons">
      
      <a href="https://hexo.io/" title="Hexo.io" target="_blank" rel="noopener" class="fas fa-home"></a>
      
      <a href="https://github.com/RandomAdversary/Gradient/issues" title="Report issue" target="_blank" rel="noopener" class="fas fa-bug"></a>
      
    </div>
  </div>
</footer>
    <!-- After footer scripts -->
    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
    crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy"
    crossorigin="anonymous"></script>
</body>

</html>